{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importacion de Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikiframe import Say, Extractor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from transform import one_hot_transform,normalize\n",
    "from utils import txt_list, get_x\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.linear_model import HuberRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciar el objeto Extractor\n",
    "extractor = Extractor('data')\n",
    "\n",
    "#Extraer en df de ./data\n",
    "df_dict = extractor.extract_from_csv()\n",
    "\n",
    "#Concatenar train y test para Hacer one hot encoding \n",
    "df_all = pd.concat([df_dict['house_train_raw'],df_dict['houses_test_raw']])\n",
    "\n",
    "#Extraer la lista de features elegidos en ./features.txt\n",
    "features = txt_list('features.txt')\n",
    "\n",
    "#Elegimos los features \n",
    "y = df_all['SalePrice']\n",
    "df_all = df_all[features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = one_hot_transform(df_all,features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizar los datos\n",
    "df_all = normalize(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['SalePrice'] = list(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando los datos como ten√≠amos antes\n",
    "train = df_all.iloc[:1460,:]\n",
    "test = df_all.iloc[1460:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[get_x(df_all)]\n",
    "y = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    #'ElasticNet': ElasticNet(random_state=0),\n",
    "    #'Lasso': Lasso(alpha=0.2),\n",
    "    #'Ridge': Ridge(alpha=1),\n",
    "    'Huber': HuberRegressor(epsilon=1.35,alpha=0.02),\n",
    "    #'RandomForest': RandomForestRegressor(),\n",
    "    #'DecisionTree': DecisionTreeRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet 0.03651677020045757\n",
      "Lasso 0.03459385021238665\n",
      "Ridge 0.03457711309539525\n",
      "Huber 0.03513054602066233\n"
     ]
    }
   ],
   "source": [
    "for name, estimator in estimators.items():\n",
    "    score = cross_val_score(estimator, X_train, y_train, cv=5, scoring='neg_mean_squared_log_error')\n",
    "    print(name, np.abs(score).min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_est = {'n_estimators': [100,200,300,400,500,600],  \n",
    "               'max_features': ['auto', 'sqrt'],  \n",
    "               'max_depth': [10, 15,20,25], \n",
    "               'min_samples_split':  [2, 5, 10], \n",
    "               'min_samples_leaf': [1, 2, 4], \n",
    "               'bootstrap': [True, False]}\n",
    "    \n",
    "params=RandomizedSearchCV(estimator=RandomForestRegressor(),param_distributions=params_est,n_iter=10,cv=5,verbose=5,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(params, X_train, y_train, cv=5, scoring='neg_mean_squared_log_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05797540442464048"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(score).min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62939cffaf3738bbc51b67feedae315a96f833a89dd775a8934aadd695f34ad2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
