{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikiframe import Say, Extractor #Extrae los csv files\n",
    "import numpy as np  #Libreria para trabajar con arrays\n",
    "import pandas as pd #Libreria para trabajar con dataframes\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "#Regresores\n",
    "from sklearn.linear_model import ElasticNet \n",
    "from sklearn.linear_model import HuberRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV,cross_val_score,KFold, GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler, OneHotEncoder, LabelEncoder,PowerTransformer, Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from mlxtend.regressor import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_log_error,  make_scorer\n",
    "scoring=make_scorer(mean_squared_log_error, greater_is_better=False, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Principales\n",
    "\n",
    "Para el desarrollo del modelo , se tomó todas la columnas de la tabla de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciar el objeto Extractor\n",
    "extractor = Extractor('data')\n",
    "\n",
    "#Extraer en df de ./data\n",
    "df_dict = extractor.extract_from_csv()\n",
    "\n",
    "#Crear dataframe con los datos\n",
    "train = df_dict['house_train_raw'].drop(['Id'],axis=1)\n",
    "test = df_dict['houses_test_raw'].drop(['Id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos en train y test\n",
    "X_train = train.drop(['SalePrice'], axis=1)\n",
    "y_train = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sepramos las varaiables categoricas y las numericas\n",
    "categorical_cols = [x for x in X_train if X_train[x].dtype == \"object\"]\n",
    "numerical_cols = [x for x in X_train if X_train[x].dtype == \"int64\" or train[x].dtype == \"float64\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elegimos los mejores Regresores\n",
    "huber_regressor = HuberRegressor()\n",
    "elastic_net = ElasticNet()\n",
    "randon_forest = RandomForestRegressor()\n",
    "ada_boost = AdaBoostRegressor()\n",
    "gradient_boost = GradientBoostingRegressor()\n",
    "xg_boost = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipelines\n",
    "\n",
    "#Pipeline para la variable categorica\n",
    "categorical = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), #Llena los NaN con el valor mas frecuentes\n",
    "    (\"oneHot\", OneHotEncoder(handle_unknown=\"ignore\")) #Codifica las variables categoricas\n",
    "])\n",
    "\n",
    "#Pipeline para la variable numerica\n",
    "numerical = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")), #Llena los NaN con la mediana de la columna\n",
    "    (\"scaler\", PowerTransformer()) #Transforma los valores de la columna, se eligió PowerTransformer porque trata de hacer gausiana la distribucion de los valores\n",
    "])\n",
    "\n",
    "#Pipeline para las variables categoricas y numericas\n",
    "preproces = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical, categorical_cols),\n",
    "        ('num', numerical, numerical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline para el modelo\n",
    "model = StackingCVRegressor(\n",
    "    regressors=[huber_regressor, elastic_net, randon_forest,ada_boost,xg_boost,gradient_boost],\n",
    "    meta_regressor=XGBRegressor()\n",
    ")\n",
    "\n",
    "#Pipeline para el modelo general\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preproces', preproces),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establecemos los parametros del modelo para que sean optimizados\n",
    "grid =RandomizedSearchCV(\n",
    "    pipe, \n",
    "    param_distributions={\n",
    "        'model__elastcnet__alpha':[0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007],\n",
    "        'model__elasticnet__l1_ratio':[0.8, 0.85, 0.9, 0.95, 0.99, 1],\n",
    "        'model__huberregressor__epsilon':np.linspace(1, 1.9, num=9),\n",
    "        'model__huberregressor__max_iter':[100,200,300,400,500,600,700,800,900,1000],\n",
    "        'model__randomforestregressor__n_estimators': [300,400,500,600],\n",
    "        'model__randomforestregressor__max_features': ['sqrt', 'log2', None],\n",
    "        'model__randomforestregressor__max_depth': [ 60, 70, 80, 90, 100,],\n",
    "        'model__randomforestregressor__min_samples_split':  [2, 5, 10],\n",
    "        'model__randomforestregressor__min_samples_leaf': [1, 2, 4],\n",
    "    },\n",
    "    cv=KFold(n_splits=5,shuffle=True), \n",
    "    n_jobs=-1, \n",
    "    verbose=1,\n",
    "    scoring=scoring,\n",
    "    n_iter=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter elasticnt for estimator StackingCVRegressor(meta_regressor=XGBRegressor(base_score=None, booster=None,\n                                                callbacks=None,\n                                                colsample_bylevel=None,\n                                                colsample_bynode=None,\n                                                colsample_bytree=None,\n                                                early_stopping_rounds=None,\n                                                enable_categorical=False,\n                                                eval_metric=None, gamma=None,\n                                                gpu_id=None, grow_policy=None,\n                                                importance_type=None,\n                                                interaction_constraints=None,\n                                                learning_rate=None,\n                                                max_bin=None,...\n                                             importance_type=None,\n                                             interaction_constraints=None,\n                                             learning_rate=None, max_bin=None,\n                                             max_cat_to_onehot=None,\n                                             max_delta_step=None,\n                                             max_depth=None, max_leaves=None,\n                                             min_child_weight=None, missing=nan,\n                                             monotone_constraints=None,\n                                             n_estimators=100, n_jobs=None,\n                                             num_parallel_tree=None,\n                                             predictor=None, random_state=None,\n                                             reg_alpha=None, reg_lambda=None, ...),\n                                GradientBoostingRegressor()]). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 436, in _process_worker\n    r = call_item()\n  File \"c:\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 288, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 668, in _fit_and_score\n    estimator = estimator.set_params(**cloned_parameters)\n  File \"c:\\Python310\\lib\\site-packages\\sklearn\\pipeline.py\", line 188, in set_params\n    self._set_params(\"steps\", **kwargs)\n  File \"c:\\Python310\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 54, in _set_params\n    super().set_params(**params)\n  File \"c:\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 258, in set_params\n    valid_params[key].set_params(**sub_params)\n  File \"c:\\Python310\\lib\\site-packages\\mlxtend\\regressor\\stacking_cv_regression.py\", line 334, in set_params\n    self._set_params(\"regressors\", \"named_regressors\", **params)\n  File \"c:\\Python310\\lib\\site-packages\\mlxtend\\utils\\base_compostion.py\", line 39, in _set_params\n    super(_BaseXComposition, self).set_params(**params)\n  File \"c:\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 245, in set_params\n    raise ValueError(\nValueError: Invalid parameter elasticnt for estimator StackingCVRegressor(meta_regressor=XGBRegressor(base_score=None, booster=None,\n                                                callbacks=None,\n                                                colsample_bylevel=None,\n                                                colsample_bynode=None,\n                                                colsample_bytree=None,\n                                                early_stopping_rounds=None,\n                                                enable_categorical=False,\n                                                eval_metric=None, gamma=None,\n                                                gpu_id=None, grow_policy=None,\n                                                importance_type=None,\n                                                interaction_constraints=None,\n                                                learning_rate=None,\n                                                max_bin=None,...\n                                             importance_type=None,\n                                             interaction_constraints=None,\n                                             learning_rate=None, max_bin=None,\n                                             max_cat_to_onehot=None,\n                                             max_delta_step=None,\n                                             max_depth=None, max_leaves=None,\n                                             min_child_weight=None, missing=nan,\n                                             monotone_constraints=None,\n                                             n_estimators=100, n_jobs=None,\n                                             num_parallel_tree=None,\n                                             predictor=None, random_state=None,\n                                             reg_alpha=None, reg_lambda=None, ...),\n                                GradientBoostingRegressor()]). Check the list of available parameters with `estimator.get_params().keys()`.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_280/262228069.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Poewr Transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RMLS: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1765\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1766\u001b[1;33m         evaluate_candidates(\n\u001b[0m\u001b[0;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m   1768\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python310\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    444\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python310\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m                 \u001b[1;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter elasticnt for estimator StackingCVRegressor(meta_regressor=XGBRegressor(base_score=None, booster=None,\n                                                callbacks=None,\n                                                colsample_bylevel=None,\n                                                colsample_bynode=None,\n                                                colsample_bytree=None,\n                                                early_stopping_rounds=None,\n                                                enable_categorical=False,\n                                                eval_metric=None, gamma=None,\n                                                gpu_id=None, grow_policy=None,\n                                                importance_type=None,\n                                                interaction_constraints=None,\n                                                learning_rate=None,\n                                                max_bin=None,...\n                                             importance_type=None,\n                                             interaction_constraints=None,\n                                             learning_rate=None, max_bin=None,\n                                             max_cat_to_onehot=None,\n                                             max_delta_step=None,\n                                             max_depth=None, max_leaves=None,\n                                             min_child_weight=None, missing=nan,\n                                             monotone_constraints=None,\n                                             n_estimators=100, n_jobs=None,\n                                             num_parallel_tree=None,\n                                             predictor=None, random_state=None,\n                                             reg_alpha=None, reg_lambda=None, ...),\n                                GradientBoostingRegressor()]). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "#Poewr Transformer\n",
    "grid.fit(X_train, y_train)\n",
    "print('RMLS: ',np.abs(grid.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "Se obtuvo una métrica del 0.0165 gracias a elegir correctamente los hyperparámetros del Pipeline. \n",
    "\n",
    "Se procederá a predecir el dataset de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = grid.predict(test)\n",
    "test['SalePrice'] = y_pred\n",
    "test.to_csv('./out/predictions.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
