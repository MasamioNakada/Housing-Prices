{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wikiframe import Say, Extractor #Extrae los csv files\n",
    "import numpy as np  #Libreria para trabajar con arrays\n",
    "import pandas as pd #Libreria para trabajar con dataframes\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "#Regresores\n",
    "from sklearn.linear_model import ElasticNet \n",
    "from sklearn.linear_model import HuberRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV,cross_val_score,KFold, GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import make_pipeline \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler,StandardScaler, OneHotEncoder,PowerTransformer, Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from mlxtend.regressor import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importamos la métrica propuesta\n",
    "\n",
    "Se utilizará para evaluar el desempeño del/los modelo/s la raíz cuadrada del error logarítmico medio, (RMSLE) por sus siglas en inglés.\n",
    "\n",
    "$$ RMSLE=\\sqrt{\\frac{1}{n}\\sum_{i=1}^n(\\log (p_i + 1)-\\log (a_i+1))^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import mean_squared_log_error,  make_scorer\n",
    "scoring=make_scorer(mean_squared_log_error, greater_is_better=False, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables Principales\n",
    "\n",
    "Para el desarrollo del modelo , se tomó todas la columnas de la tabla de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciar el objeto Extractor\n",
    "extractor = Extractor('data')\n",
    "\n",
    "#Extraer en df de ./data\n",
    "df_dict = extractor.extract_from_csv()\n",
    "\n",
    "#Crear dataframe con los datos\n",
    "train = df_dict['house_train_raw'].drop(['Id'],axis=1)\n",
    "test = df_dict['houses_test_raw'].drop(['Id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('https://raw.githubusercontent.com/MasamioNakada/Housing-Prices/main/data/house_train_raw.csv')\n",
    "test = pd.read_csv('https://raw.githubusercontent.com/MasamioNakada/Housing-Prices/main/data/houses_test_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos en train y test\n",
    "X = train.drop(['SalePrice'], axis=1)\n",
    "y = train['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sepramos las varaiables categoricas y las numericas\n",
    "categorical_cols = [x for x in X if X[x].dtype == \"object\"]\n",
    "numerical_cols = [x for x in X if X[x].dtype == \"int64\" or train[x].dtype == \"float64\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformación de Datos\n",
    "\n",
    "- Para la variables categoricas , se realizó one-hot encoding, Cuando hay valores nulos simplemente a las columnas correspondientes será 0.\n",
    "- Para las variables numéricas , si se encuentra un valor nulo, se le asignará la mediana de la columna correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipelines\n",
    "\n",
    "#Pipeline para la variable categorica\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "categorical = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), #Llena los NaN con el valor mas frecuentes\n",
    "    (\"oneHot\", OneHotEncoder(handle_unknown=\"ignore\")) #Codifica las variables categoricas\n",
    "])\n",
    "\n",
    "#Pipeline para la variable numerica\n",
    "numerical = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")), #Llena los NaN con la mediana de la columna\n",
    "    (\"scaler\", MinMaxScaler()) #Transforma los valores de la columna, se eligió PowerTransformer porque trata de hacer gausiana la distribucion de los valores\n",
    "])\n",
    "\n",
    "#Pipeline para las variables categoricas y numericas\n",
    "preproces = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical, categorical_cols),\n",
    "        ('num', numerical, numerical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo\n",
    "\n",
    "Se decidió utilizar **StackingRegressor** para enriquecer el modelo con distintos regresores.\n",
    "- ElasticNetRegressor : En el EDA se observó que habia columnas que estabam altamente correlacionas. Este regresor es la conjunción de RidgeRegressor y LassoRegressor que su objetivo es penalizar esas columnas que podrían o no aportar al modelo.\n",
    "- HuberRegressor : En el EDA se observó que había outiliers , por lo que a este regresor no le impacta muchos estos datos atípicos.\n",
    "- ADABoostRegressor : Este regresor es menos propenso al sobreajuste ya que los parámetros de entrada no se optimizan conjuntamente. \n",
    "- RandonForestRegressor : En el entrenamiento por individual, este regresor dió los mejores resultados.\n",
    "- XGBoostRegressor : En el entrenamiento por individual, este regresor dió los mejores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Elegimos los mejores Regresores\n",
    "huber_regressor = HuberRegressor()\n",
    "elastic_net = ElasticNet()\n",
    "randon_forest = RandomForestRegressor()\n",
    "ada_boost = AdaBoostRegressor()\n",
    "gradient_boost = GradientBoostingRegressor()\n",
    "xg_boost = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Utilizamos StackingCVRegressor para combinar los regresores y tner una mejor estimacion\n",
    "model = StackingCVRegressor(\n",
    "    regressors=[huber_regressor, elastic_net, randon_forest,ada_boost,xg_boost],\n",
    "    meta_regressor=elastic_net\n",
    ")\n",
    "\n",
    "#Pipeline para el modelo general\n",
    "pipe = Pipeline(steps=[\n",
    "    ('  ', preproces),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "scoring(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establecemos los parametros del modelo para que sean optimizados\n",
    "grid =RandomizedSearchCV(\n",
    "    pipe, \n",
    "    param_distributions={\n",
    "\n",
    "        'model__xgbregressor__min_child_weight':np.arange(1,10,1),\n",
    "        'model__xgbregressor__learning_rate':np.arange(0.01,1,0.01),\n",
    "        'model__xgbregressor__n_estimators':np.arange(1100,2000,80),\n",
    "        \n",
    "        \n",
    "        'model__elasticnet__alpha':np.arange(0.2,1,0.1),\n",
    "        'model__elasticnet__l1_ratio':np.arange(0.2,1,0.1),\n",
    "\n",
    "        \n",
    "        'model__randomforestregressor__n_estimators': np.arange(100,2000,100),\n",
    "        'model__randomforestregressor__max_features': ['sqrt', 'log2', None],\n",
    "        'model__randomforestregressor__max_depth': [ 60, 70, 80, 90, 100,],\n",
    "        'model__randomforestregressor__min_samples_split':  [2, 5, 10],\n",
    "        'model__randomforestregressor__min_samples_leaf': [1, 2, 4],\n",
    "\n",
    "    },\n",
    "    cv=KFold(n_splits=5,shuffle=True), \n",
    "    n_jobs=-1, \n",
    "    verbose=1,\n",
    "    scoring=scoring,\n",
    "    n_iter=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para saber los nombres de los paramatros que queremos optimizar en RandomizedSearchCV\n",
    "for param in grid.get_params().keys():\n",
    "    print(param)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "RMLS:  0.12476997462084531\n"
     ]
    }
   ],
   "source": [
    "grid.fit(X_train, y_train)\n",
    "print('RMLS: ',np.abs(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ___________________________ \n",
      "< RMLS: 0.12476997462084531 > \n",
      " --------------------------- \n",
      "        \\   ^__^ \n",
      "         \\  (oo)\\_______ \n",
      "            (__)\\ good🥇 )\\/\\ \n",
      "                ||----w | \n",
      "                ||     || \n"
     ]
    }
   ],
   "source": [
    "Say(f'RMLS: {np.abs(grid.best_score_)}').cow_says_good()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "Se obtuvo una métrica del 0.13 gracias a elegir correctamente los hyperparámetros del Pipeline. \n",
    "\n",
    "Se procederá a predecir el dataset de Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " _____________________ \n",
      "< ./out/pred_test.csv > \n",
      " --------------------- \n",
      "        \\   ^__^ \n",
      "         \\  (oo)\\_______ \n",
      "            (__)\\ good🛐 )\\/\\ \n",
      "                ||----w | \n",
      "                ||     || \n",
      " ___________________________ \n",
      "< ./out/houses_test_raw.csv > \n",
      " --------------------------- \n",
      "        \\   ^__^ \n",
      "         \\  (oo)\\_______ \n",
      "            (__)\\ good🥇 )\\/\\ \n",
      "                ||----w | \n",
      "                ||     || \n"
     ]
    }
   ],
   "source": [
    "#Obtenemos la prediccion \n",
    "y_pred = pd.DataFrame(grid.predict(test),columns=['pred'])\n",
    "path_pred = './out/pred_test.csv'\n",
    "y_pred.to_csv(path_pred) #-> Guardamos solo la columna predicion\n",
    "\n",
    "Say(path_pred).cow_says_good()\n",
    "\n",
    "test['SalePrice'] = y_pred\n",
    "path_all = './out/houses_test_raw.csv'\n",
    "test.to_csv(path_all,index=False)\n",
    "\n",
    "Say(path_all).cow_says_good()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
